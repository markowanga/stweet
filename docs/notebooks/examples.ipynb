{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are simple examples of using stweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stweet as st\n",
    "import arrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scrap tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap tweets with `#covid19` between `'2020-05-11T20:00:00.000+01:00'` and `'2020-05-11T20:01:00.000+01:00'`.\n",
    "Collect all tweets in memory and save to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = st.SearchTweetsTask(\n",
    "    '#covid19',\n",
    "    since=arrow.get('2020-05-11T20:00:00.000+01:00'),\n",
    "    until=arrow.get('2020-05-11T20:01:00.000+01:00')\n",
    ")\n",
    "tweets_collector = st.CollectorTweetOutput()\n",
    "result = st.TweetSearchRunner(task, [tweets_collector, st.CsvTweetOutput('covid19_tweets.csv')]).run()\n",
    "print(f'scrapping task result: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first tweet content:')\n",
    "print(tweets_collector.get_scrapped_tweets()[0].full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'first tweet time: {tweets_collector.get_scrapped_tweets()[0].created_at}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapped time have different hour than was input in task, but everything is ok because scrapped tweet has no time offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap first 70 tweets with exact phrase `crypto is awesome` and save them in memory and in JSON lines file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = st.SearchTweetsTask(\n",
    "    exact_words='crypto is awesome',\n",
    "    tweets_limit=70\n",
    ")\n",
    "tweets_collector = st.CollectorTweetOutput()\n",
    "result = st.TweetSearchRunner(task, [tweets_collector, st.JsonLineFileTweetOutput('covid19_tweets.jl')]).run()\n",
    "print(f'scrapping task result: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('first tweet content:')\n",
    "print(tweets_collector.get_scrapped_tweets()[0].full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('last tweet content:')\n",
    "print(tweets_collector.get_scrapped_tweets()[-1].full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap first 1000 tweets with any of hashtags: `#covid19` or `#bbc` using proxy. Save it in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = st.SearchTweetsTask(\n",
    "    any_word='#covid19 #bbc',\n",
    "    tweets_limit=1000\n",
    ")\n",
    "web_client = st.RequestsWebClient(\n",
    "    proxy=st.RequestsWebClientProxyConfig(http_proxy='', https_proxy='')\n",
    ")\n",
    "tweets_collector = st.CollectorTweetOutput()\n",
    "result = st.TweetSearchRunner(task, [tweets_collector], web_client=web_client).run()\n",
    "print(f'scrapping task result: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter index hashtags without case sensitive. There is a need to create simple function to check that tweet contains hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cointain_hashtag(tweet: st.Tweet, hashtag: str) -> bool:\n",
    "    return hashtag.lower() in tweet.full_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_collector.get_scrapped_tweets()\n",
    "\n",
    "print('both count:', len([\n",
    "    it for it in tweets \n",
    "    if tweet_cointain_hashtag(it, '#bbc') and tweet_cointain_hashtag(it, '#covid19')\n",
    "]))\n",
    "print('only #covid19 count:', len([it for it in tweets if tweet_cointain_hashtag(it, '#covid19')]))\n",
    "print('only #bbc count:', len([it for it in tweets if tweet_cointain_hashtag(it, '#bbc')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap tweets by ids and save in memory, check that all are existing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = st.TweetsByIdsTask(['1337071849772093442', '1337067073051238400'])\n",
    "tweets_collector = st.CollectorTweetOutput()\n",
    "\n",
    "result = st.TweetsByIdsRunner(task, [tweets_collector]).run()\n",
    "scrapped_tweets_ids = [it.id_str for it in tweets_collector.get_scrapped_tweets()]\n",
    "\n",
    "print('tweet ids not scrapped:', result.tweet_ids_not_scrapped)\n",
    "print('scrapped tweets count:', len(tweets_collector.get_scrapped_tweets()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrap users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap users by usernames. Save them into memry, CSV and JSON lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = ['ProtasiewiczJ', 'donaldtuskEPP']\n",
    "task = st.GetUsersTask(usernames)\n",
    "\n",
    "user_collector = st.CollectorUserOutput()\n",
    "outputs = [\n",
    "    st.CsvUserOutput('users.csv'),\n",
    "    st.JsonLineFileUserOutput('users.jl'),\n",
    "    user_collector\n",
    "]\n",
    "\n",
    "task_result = st.GetUsersRunner(task, outputs).run()\n",
    "[it.screen_name for it in user_collector.get_scrapped_users()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export previous scrapped tweets into CSV and JSON line file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_collector.get_scrapped_tweets()\n",
    "st.export_tweets_to_csv(tweets, 'export_tweets.csv')\n",
    "st.export_tweets_to_json_lines(tweets, 'export_tweets.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export previous scrapped users into CSV and JSON line file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = user_collector.get_scrapped_users()\n",
    "st.export_users_to_csv(users, 'export_users.csv')\n",
    "st.export_users_to_json_lines(users, 'export_users.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tweets from JSON lines file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = st.read_tweets_from_json_lines_file('export_tweets.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tweets from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = st.read_tweets_from_csv_file('export_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import users from JSON lines file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = st.read_users_from_json_lines_file('export_users.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import users from CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = st.read_users_from_csv_file('export_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}